{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9afcff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lv4\n",
    "#date: 21/09/2022\n",
    "#update 1: dlg only considers two sentences\n",
    "#update 2: remove ' \" “ ” ‘ ’ in the sentence\n",
    "#update 3: change the format of output\n",
    "#update 4: write all the results in one json\n",
    "#use English to annotate the codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "424e656e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "#load the priginal dataset\n",
    "JsonText = open('dialog_release.json',encoding='utf-8')\n",
    "JsonText = json.load(JsonText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d475413",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19919\n"
     ]
    }
   ],
   "source": [
    "#length of the dataset\n",
    "print(len(JsonText))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73979c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dialog_id': '0_2', 'document_id': 0, 'content': ['嗨！', '你好。', '你最近有听说过《中国女排》这部电影嘛？', '不好意思唉，我已经很久没有去关注电影了，你可以给我讲述一下这是什么电影嘛。', '当然可以了，这部片子主要是讲述了女排这些年的历史，而且听说这部戏里面的郎平教练会是巩俐来出演。', '真的啊，我觉得我都好久没有看过巩俐的电影了，我突然好期待这部电影啊。', '是呀，我觉得这部《中国女排》应该能拿下很高的收视率。', '肯定会的，毕竟这也是中宣部与国家体育总局联合拍摄，肯定是会很好看的。', '也是哈，毕竟后面还有国家呢，应该也不会差到哪里去的。', '哎呀，你这说我真的好期待的啊。', '嘿嘿，好像在过年的时候就会上映，也没有多久了。', '也是哈，不过我听说巩俐还会参演迪士尼出品的那部《花木兰》是吧。', '是的，不过这段时间不是说，迪士尼在抹黑中国文化嘛。', '你说的是之前发出来的预告片里面的妆容太过于浓重的事情吧。', '是啊，毕竟我们中国的历史上也没有过那么浓重的妆容吧。', '这就不知道，毕竟也我们中国曾经有过那么多的国家，谁知道他们从哪里找来的妆容呢。', '也是哈，不过花木兰不是南北朝的人嘛，用得妆容也应该要符合这个朝代吧。', '但是谁也不知道那个时候的妆容是什么样子的呀，也只能根据那些古画和文献来推理。', '这就难说了，反正到时候出来了好看就看呗，也没有逼着我们去看呐。', '你说得也对，想不想看也是我们自己的意思。', '哎呀，我要去吃饭了，再见哈！', '好的，再见。']}\n"
     ]
    }
   ],
   "source": [
    "#wxample in the dataset\n",
    "print(JsonText[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8683512",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove ' \" “ ” ‘ ’ in content\n",
    "for dictionary in JsonText:\n",
    "    for n in range(len(dictionary['content'])):\n",
    "        dictionary['content'][n] = dictionary['content'][n].replace(\"'\", \"\").replace('''\"''', \"\").replace(\"“\", \"\").replace(\"”\", \"\").replace(\"‘\", \"\").replace(\"’\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e309f6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep content\n",
    "dialogs = []\n",
    "for n in range(len(JsonText)):\n",
    "    dialogs.append(JsonText[n]['content'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "27e2d6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19919\n",
      "['嗨！', '你好。', '你最近有听说过《中国女排》这部电影嘛？', '不好意思唉，我已经很久没有去关注电影了，你可以给我讲述一下这是什么电影嘛。', '当然可以了，这部片子主要是讲述了女排这些年的历史，而且听说这部戏里面的郎平教练会是巩俐来出演。', '真的啊，我觉得我都好久没有看过巩俐的电影了，我突然好期待这部电影啊。', '是呀，我觉得这部《中国女排》应该能拿下很高的收视率。', '肯定会的，毕竟这也是中宣部与国家体育总局联合拍摄，肯定是会很好看的。', '也是哈，毕竟后面还有国家呢，应该也不会差到哪里去的。', '哎呀，你这说我真的好期待的啊。', '嘿嘿，好像在过年的时候就会上映，也没有多久了。', '也是哈，不过我听说巩俐还会参演迪士尼出品的那部《花木兰》是吧。', '是的，不过这段时间不是说，迪士尼在抹黑中国文化嘛。', '你说的是之前发出来的预告片里面的妆容太过于浓重的事情吧。', '是啊，毕竟我们中国的历史上也没有过那么浓重的妆容吧。', '这就不知道，毕竟也我们中国曾经有过那么多的国家，谁知道他们从哪里找来的妆容呢。', '也是哈，不过花木兰不是南北朝的人嘛，用得妆容也应该要符合这个朝代吧。', '但是谁也不知道那个时候的妆容是什么样子的呀，也只能根据那些古画和文献来推理。', '这就难说了，反正到时候出来了好看就看呗，也没有逼着我们去看呐。', '你说得也对，想不想看也是我们自己的意思。', '哎呀，我要去吃饭了，再见哈！', '好的，再见。']\n"
     ]
    }
   ],
   "source": [
    "print(len(dialogs))\n",
    "print(dialogs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f56bd17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AB = [\"A\", \"B\"]\n",
    "results_NaturalConv = []\n",
    "\n",
    "for m in list(range(0, 6250)) + list(range(6251, 6258)) + list(range(6259, 8114)) + list(range(8115, 9041)) + list(range(9042, 9333)) + list(range(9334, 9356)) + list(range(9358, 10318)) + list(range(10319, 10665)) + list(range(10667, 18768)) + list(range(18769, 19464)) + list(range(19465, 19753)) + list(range(19754, len(dialogs))):\n",
    "    \n",
    "    dialog = dialogs[m]\n",
    "    ques_index = 0\n",
    "    \n",
    "    #if dailog has more than three sentences\n",
    "    if len(dialog) >=3:\n",
    "        \n",
    "        #find the last sentence ending with ？\n",
    "        for sent_index in range(len(dialog)):\n",
    "            if (dialog[sent_index].endswith('？')) and (sent_index >= 1) and (sent_index <= len(dialog)-2):\n",
    "                ques_index = sent_index\n",
    "        \n",
    "        #if this snetence has previous and subsequent sentences\n",
    "        if (ques_index >= 1) and (ques_index <= len(dialog)-2):\n",
    "            \n",
    "            ##print all the previous sentences, this sentence, and subsequent two sentences\n",
    "            #for n in range(ques_index+2):\n",
    "            #    print(dialog[n])\n",
    "            #print('------------')\n",
    "            \n",
    "            #unfilled json\n",
    "            jsontext ={\"Source\":\"NaturalConv\",\"Topic\":\"\",\"Components\":{\"talkers\":[\"A\",\"B\"],\"dlg\":[],\"qak\":[{}, {}],\"query\":{\"talker\":'',\"text\":\"\"},\"mask\":{\"talker\":'',\"text\":\"[sMASK]\"},\"postdlg\":[]}, \"Fomats\":{\"intra_utter_form\":\"{talker}:{text}\",\"inter_utter_token\":\"\",\"prompt_form\":\"\"}, \"Input\":\"对话：\", \"Output\":\"\"} \n",
    "            \n",
    "            #fill dlg in json\n",
    "            for n in [ques_index-2]:\n",
    "                jsontext[\"Components\"][\"dlg\"].append({\"talker\":0})\n",
    "                if n%2 == 0:\n",
    "                    jsontext[\"Components\"][\"dlg\"][0][\"talker\"] = 0\n",
    "                else:\n",
    "                    jsontext[\"Components\"][\"dlg\"][0][\"talker\"] = 1\n",
    "                jsontext[\"Components\"][\"dlg\"][0][\"text\"] = dialog[n]\n",
    "                jsontext['Input'] = jsontext['Input'] + AB[n%2] + '：' + dialog[n]\n",
    "                \n",
    "            for n in [ques_index-1]:\n",
    "                jsontext[\"Components\"][\"dlg\"].append({\"talker\":0})\n",
    "                if n%2 == 0:\n",
    "                    jsontext[\"Components\"][\"dlg\"][1][\"talker\"] = 0\n",
    "                else:\n",
    "                    jsontext[\"Components\"][\"dlg\"][1][\"talker\"] = 1\n",
    "                jsontext[\"Components\"][\"dlg\"][1][\"text\"] = dialog[n]\n",
    "                jsontext['Input'] = jsontext['Input'] + AB[n%2] + '：' + dialog[n]\n",
    "            \n",
    "            #fill qak in json\n",
    "            jsontext[\"Components\"]['qak'][0]['talker'] = ques_index%2\n",
    "            jsontext[\"Components\"]['qak'][0]['text'] = dialog[ques_index]\n",
    "            jsontext[\"Components\"]['qak'][1]['talker'] = (ques_index+1)%2\n",
    "            jsontext[\"Components\"]['qak'][1]['text'] = dialog[ques_index+1]\n",
    "            jsontext['Input'] = jsontext['Input'] + AB[ques_index%2] + '：' + dialog[ques_index] + AB[(ques_index+1)%2] + '：' + dialog[ques_index+1]\n",
    "            \n",
    "            #fill query in json\n",
    "            jsontext[\"Components\"]['query']['talker'] = ques_index%2\n",
    "            jsontext[\"Components\"]['query']['text'] = dialog[ques_index]\n",
    "            jsontext['Input'] = jsontext['Input'] + AB[ques_index%2] + '：' + dialog[ques_index]\n",
    "            \n",
    "            \n",
    "            #fill mask in json\n",
    "            jsontext['Input'] = jsontext['Input'] + AB[(ques_index+1)%2] + '：' + '[sMASK]'\n",
    "            jsontext['Output'] = dialog[ques_index+1]\n",
    "            jsontext[\"Components\"]['mask'][\"talker\"]=(ques_index+1)%2\n",
    "            \n",
    "            #fill postdlg in json\n",
    "            if ques_index+2 < len(dialog):\n",
    "                for n in range((len(dialog)-1) - (ques_index+2) + 1):\n",
    "                    jsontext[\"Components\"]['postdlg'].append({\"talker\":0})\n",
    "                    jsontext[\"Components\"]['postdlg'][n][\"talker\"] = (ques_index+1+n+1)%2\n",
    "                    jsontext[\"Components\"]['postdlg'][n][\"text\"] = dialog[ques_index+1+n+1]\n",
    "                    jsontext['Input'] = jsontext['Input'] + AB[(ques_index+1+n+1)%2] + '：' + dialog[ques_index+1+n+1]\n",
    "            \n",
    "            #fill Formats in json\n",
    "            if (jsontext[\"Components\"]['mask'][\"talker\"] == 0) and (ques_index+2 < len(dialog)):\n",
    "                jsontext[\"Fomats\"][\"prompt_form\"] = \"对话：{concat([dlg,qak,query])} {talkers[0]}:[sMASK]{concat([postdlg])})\"\n",
    "                \n",
    "            elif (jsontext[\"Components\"]['mask'][\"talker\"] == 0) and (ques_index+2 >= len(dialog)):\n",
    "                jsontext[\"Fomats\"][\"prompt_form\"] = \"对话：{concat([dlg,qak,query])} {talkers[0]}:[sMASK])\"\n",
    "            \n",
    "            elif (jsontext[\"Components\"]['mask'][\"talker\"] == 1) and (ques_index+2 < len(dialog)):\n",
    "                jsontext[\"Fomats\"][\"prompt_form\"] = \"对话：{concat([dlg,qak,query])} {talkers[1]}:[sMASK]{concat([postdlg])})\"\n",
    "                \n",
    "            elif (jsontext[\"Components\"]['mask'][\"talker\"] == 1) and (ques_index+2 >= len(dialog)):\n",
    "                jsontext[\"Fomats\"][\"prompt_form\"] = \"对话：{concat([dlg,qak,query])} {talkers[1]}:[sMASK])\"\n",
    "            \n",
    "            results_NaturalConv.append(jsontext)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff30687",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the json\n",
    "with open('./results_NaturalConv.json', 'w', encoding = 'utf-8') as json_file:\n",
    "    #transform dict to str\n",
    "    json_str = json.dumps(results_NaturalConv,indent=4,ensure_ascii=False)\n",
    "    json_file.write(json_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c301fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a412f23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
